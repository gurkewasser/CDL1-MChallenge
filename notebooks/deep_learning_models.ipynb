{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rootutils\n",
    "\n",
    "root = rootutils.setup_root(search_from=\".\", indicator=\".git\")\n",
    "\n",
    "DATA_DIR_TRAIN = root / \"data\" / \"DL\" / \"TRAIN\"\n",
    "DATA_DIR_TEST = root / \"data\" / \"DL\" / \"TEST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_data_path_train = DATA_DIR_TRAIN / \"dl_data_train.npz\"\n",
    "dl_data_path_test = DATA_DIR_TEST / \"dl_data_test.npz\"\n",
    "dl_data_train = np.load(dl_data_path_train, allow_pickle=True)\n",
    "dl_data_test = np.load(dl_data_path_test, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NpzFile '/Users/denizhatemo/Desktop/CDL1Challenge/CDL1-MChallenge/data/DL/TRAIN/dl_data_train.npz' with keys: X, y\n",
      "Keys: ['X', 'y']\n",
      "X: shape=(2879, 250, 20), dtype=float32\n",
      "y: shape=(2879,), dtype=object\n",
      "NpzFile '/Users/denizhatemo/Desktop/CDL1Challenge/CDL1-MChallenge/data/DL/TEST/dl_data_test.npz' with keys: X, y\n",
      "Keys: ['X', 'y']\n",
      "X: shape=(1250, 250, 20), dtype=float32\n",
      "y: shape=(1250,), dtype=object\n"
     ]
    }
   ],
   "source": [
    "print(dl_data_train)\n",
    "print(\"Keys:\", dl_data_train.files)\n",
    "for key in dl_data_train.files:\n",
    "    print(f\"{key}: shape={dl_data_train[key].shape}, dtype={dl_data_train[key].dtype}\")\n",
    "\n",
    "print(dl_data_test)\n",
    "print(\"Keys:\", dl_data_test.files)\n",
    "for key in dl_data_test.files:\n",
    "    print(f\"{key}: shape={dl_data_test[key].shape}, dtype={dl_data_test[key].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN\n",
    "LSTM\n",
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'climbing': np.int64(0), 'joggen': np.int64(1), 'sitting': np.int64(2), 'walking': np.int64(3)}\n",
      "Epoch 1/20 - Train loss: 0.8301 - Val loss: 0.6546 - Val acc: 0.8445\n",
      "Epoch 2/20 - Train loss: 0.4598 - Val loss: 0.4258 - Val acc: 0.8585\n",
      "Epoch 3/20 - Train loss: 0.3745 - Val loss: 0.3824 - Val acc: 0.8677\n",
      "Epoch 4/20 - Train loss: 0.3490 - Val loss: 0.3568 - Val acc: 0.8608\n",
      "Epoch 5/20 - Train loss: 0.3300 - Val loss: 0.3451 - Val acc: 0.8770\n",
      "Epoch 6/20 - Train loss: 0.3233 - Val loss: 0.3490 - Val acc: 0.8677\n",
      "Epoch 7/20 - Train loss: 0.3087 - Val loss: 0.3268 - Val acc: 0.8654\n",
      "Epoch 8/20 - Train loss: 0.2796 - Val loss: 0.3037 - Val acc: 0.8886\n",
      "Epoch 9/20 - Train loss: 0.2687 - Val loss: 0.3056 - Val acc: 0.8770\n",
      "Epoch 10/20 - Train loss: 0.2575 - Val loss: 0.2848 - Val acc: 0.8840\n",
      "Epoch 11/20 - Train loss: 0.2440 - Val loss: 0.2782 - Val acc: 0.9002\n",
      "Epoch 12/20 - Train loss: 0.2408 - Val loss: 0.2614 - Val acc: 0.9026\n",
      "Epoch 13/20 - Train loss: 0.2300 - Val loss: 0.2706 - Val acc: 0.9095\n",
      "Epoch 14/20 - Train loss: 0.2336 - Val loss: 0.2556 - Val acc: 0.9142\n",
      "Epoch 15/20 - Train loss: 0.2230 - Val loss: 0.2448 - Val acc: 0.9072\n",
      "Epoch 16/20 - Train loss: 0.2068 - Val loss: 0.2275 - Val acc: 0.9258\n",
      "Epoch 17/20 - Train loss: 0.2171 - Val loss: 0.2356 - Val acc: 0.9118\n",
      "Epoch 18/20 - Train loss: 0.1987 - Val loss: 0.2158 - Val acc: 0.9397\n",
      "Epoch 19/20 - Train loss: 0.2162 - Val loss: 0.2380 - Val acc: 0.9281\n",
      "Epoch 20/20 - Train loss: 0.1751 - Val loss: 0.2027 - Val acc: 0.9304\n",
      "Test Accuracy: 0.9515\n",
      "Test Precision: 0.9537\n",
      "Test Recall: 0.9515\n",
      "Test F1-score: 0.9519\n",
      "Example true labels: ['climbing' 'climbing' 'walking' 'joggen' 'sitting' 'walking' 'joggen'\n",
      " 'walking' 'walking' 'climbing']\n",
      "Example predicted labels: ['climbing' 'climbing' 'walking' 'joggen' 'sitting' 'walking' 'joggen'\n",
      " 'walking' 'walking' 'climbing']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data\n",
    "X = dl_data_train['X']  # shape: (N, T, C) or (N, C, T)\n",
    "y = dl_data_train['y']  # shape: (N,)\n",
    "\n",
    "# If y is object dtype or string, encode to integer labels\n",
    "if y.dtype.kind in {'U', 'S', 'O'} or not np.issubdtype(y.dtype, np.integer):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    print(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "else:\n",
    "    le = None  # No label encoding needed\n",
    "\n",
    "if X.shape[1] < X.shape[2]:  # (N, T, C) -> (N, C, T)\n",
    "    X = np.transpose(X, (0, 2, 1))\n",
    "\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "\n",
    "# Split into train, val, test (e.g., 70/15/15)\n",
    "N = X.shape[0]\n",
    "n_train = int(0.7 * N)\n",
    "n_val = int(0.15 * N)\n",
    "n_test = N - n_train - n_val\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_set, val_set, test_set = random_split(dataset, [n_train, n_val, n_test], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "# Define a simple 1D CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 32, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(in_channels=X.shape[1], num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, epochs=20):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                val_loss += loss.item() * xb.size(0)\n",
    "                preds = out.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.append(preds)\n",
    "                all_labels.append(yb.cpu().numpy())\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = accuracy_score(np.concatenate(all_labels), np.concatenate(all_preds))\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.4f} - Val loss: {val_loss:.4f} - Val acc: {val_acc:.4f}\")\n",
    "\n",
    "train_model(model, train_loader, val_loader, epochs=20)\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = model(xb)\n",
    "        preds = out.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(yb.cpu().numpy())\n",
    "y_true = np.concatenate(all_labels)\n",
    "y_pred = np.concatenate(all_preds)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Test Precision: {prec:.4f}\")\n",
    "print(f\"Test Recall: {rec:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")\n",
    "\n",
    "# If you want to map predictions back to string labels:\n",
    "if le is not None:\n",
    "    y_true_labels = le.inverse_transform(y_true)\n",
    "    y_pred_labels = le.inverse_transform(y_pred)\n",
    "    print(\"Example true labels:\", y_true_labels[:10])\n",
    "    print(\"Example predicted labels:\", y_pred_labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdl1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
